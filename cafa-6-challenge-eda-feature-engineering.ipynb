{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:47.000188Z",
     "iopub.status.busy": "2025-11-08T16:33:46.999835Z",
     "iopub.status.idle": "2025-11-08T16:33:47.357201Z",
     "shell.execute_reply": "2025-11-08T16:33:47.356224Z",
     "shell.execute_reply.started": "2025-11-08T16:33:47.000157Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# competition_folder = '/kaggle/input/cafa-6-protein-function-prediction/'\n",
    "competition_folder = 'data'\n",
    "\n",
    "list_of_filenames = []\n",
    "for dirname, _, filenames in os.walk(competition_folder):\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(dirname, filename)\n",
    "        list_of_filenames.append(filepath)\n",
    "        print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------\n",
    "-------\n",
    "# Install Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Bio fair-esm goatools propy3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------\n",
    "-------\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Bio import SeqIO\n",
    "from goatools.obo_parser import GODag\n",
    "from propy import PyPro\n",
    "from propy.GetProteinFromUniprot import GetProteinSequence\n",
    "import esm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------\n",
    "-------\n",
    "# Observe File Contents (Terminal)\n",
    "First, let's have a look at the first few lines of each file to know what we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:48.016621Z",
     "iopub.status.busy": "2025-11-08T16:33:48.016235Z",
     "iopub.status.idle": "2025-11-08T16:33:48.144989Z",
     "shell.execute_reply": "2025-11-08T16:33:48.143408Z",
     "shell.execute_reply.started": "2025-11-08T16:33:48.016580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_sequences_file = competition_folder + '/Train/train_sequences.fasta'\n",
    "!head {train_sequences_file} -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:47.887466Z",
     "iopub.status.busy": "2025-11-08T16:33:47.887148Z",
     "iopub.status.idle": "2025-11-08T16:33:48.014718Z",
     "shell.execute_reply": "2025-11-08T16:33:48.013382Z",
     "shell.execute_reply.started": "2025-11-08T16:33:47.887436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_terms_file = competition_folder + '/Train/train_terms.tsv'\n",
    "!head {train_terms_file} -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:48.147090Z",
     "iopub.status.busy": "2025-11-08T16:33:48.146704Z",
     "iopub.status.idle": "2025-11-08T16:33:48.275459Z",
     "shell.execute_reply": "2025-11-08T16:33:48.274154Z",
     "shell.execute_reply.started": "2025-11-08T16:33:48.147051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_taxonomy_file = competition_folder + '/Train/train_taxonomy.tsv'\n",
    "!head {train_taxonomy_file} -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:47:44.730002Z",
     "iopub.status.busy": "2025-11-08T16:47:44.729026Z",
     "iopub.status.idle": "2025-11-08T16:47:44.876797Z",
     "shell.execute_reply": "2025-11-08T16:47:44.875809Z",
     "shell.execute_reply.started": "2025-11-08T16:47:44.729944Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "go_file = competition_folder + '/Train/go-basic.obo'\n",
    "!head {go_file} -n 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:47.624112Z",
     "iopub.status.busy": "2025-11-08T16:33:47.623778Z",
     "iopub.status.idle": "2025-11-08T16:33:47.753652Z",
     "shell.execute_reply": "2025-11-08T16:33:47.752374Z",
     "shell.execute_reply.started": "2025-11-08T16:33:47.624084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testsuperset_file = competition_folder + '/Test/testsuperset.fasta'\n",
    "!head {testsuperset_file} -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:47.756009Z",
     "iopub.status.busy": "2025-11-08T16:33:47.755150Z",
     "iopub.status.idle": "2025-11-08T16:33:47.886069Z",
     "shell.execute_reply": "2025-11-08T16:33:47.884704Z",
     "shell.execute_reply.started": "2025-11-08T16:33:47.755965Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "testsuperset_taxon_file = competition_folder + '/Test/testsuperset-taxon-list.tsv'\n",
    "!head {testsuperset_taxon_file} -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:47.492075Z",
     "iopub.status.busy": "2025-11-08T16:33:47.491791Z",
     "iopub.status.idle": "2025-11-08T16:33:47.621562Z",
     "shell.execute_reply": "2025-11-08T16:33:47.620349Z",
     "shell.execute_reply.started": "2025-11-08T16:33:47.492047Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ia_file = competition_folder + '/IA.tsv'\n",
    "!head {ia_file} -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:33:47.359387Z",
     "iopub.status.busy": "2025-11-08T16:33:47.358814Z",
     "iopub.status.idle": "2025-11-08T16:33:47.490599Z",
     "shell.execute_reply": "2025-11-08T16:33:47.489022Z",
     "shell.execute_reply.started": "2025-11-08T16:33:47.359359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_submission_file = competition_folder + '/sample_submission.tsv'\n",
    "!head {sample_submission_file} -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------\n",
    "-------\n",
    "# EDA\n",
    "We shall load the different files, get some stats on the data, and observe some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species Lookup\n",
    "The spiecies IDs and their corresponding names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# species lookup table\n",
    "\n",
    "species_lookup_df = pd.read_csv(testsuperset_taxon_file, sep=\"\\t\")\n",
    "species_lookup_df.columns = ['species_id', 'species_name']\n",
    "species_lookup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FASTA Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files containing the FASTA sequences\n",
    "\n",
    "train_fasta_sequences = [{\"id\": record.id, \"seq\": record.seq} for record in SeqIO.parse(train_sequences_file, \"fasta\")]\n",
    "test_fasta_sequences  = [{\"id\": record.id, \"seq\": record.seq} for record in SeqIO.parse(testsuperset_file,    \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:35.297375Z",
     "iopub.status.busy": "2025-11-08T16:34:35.296934Z",
     "iopub.status.idle": "2025-11-08T16:34:38.905309Z",
     "shell.execute_reply": "2025-11-08T16:34:38.904344Z",
     "shell.execute_reply.started": "2025-11-08T16:34:35.297350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# number of FASTA sequences in train & test sets\n",
    "\n",
    "print(f\"len(train_fasta_sequences) = {len(train_fasta_sequences)}\")\n",
    "print(f\"len(test_fasta_sequences)  = {len(test_fasta_sequences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:38.906734Z",
     "iopub.status.busy": "2025-11-08T16:34:38.906390Z",
     "iopub.status.idle": "2025-11-08T16:34:38.913089Z",
     "shell.execute_reply": "2025-11-08T16:34:38.912007Z",
     "shell.execute_reply.started": "2025-11-08T16:34:38.906693Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# look at data sample (first 3 examples of train set)\n",
    "\n",
    "for record in train_fasta_sequences[:3]:\n",
    "    print(record['id'])\n",
    "    print(record['seq'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(str(entry[\"seq\"])) for entry in train_fasta_sequences]\n",
    "\n",
    "bin_width = 100\n",
    "bins = np.arange(0, max(lengths) + bin_width, bin_width)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(lengths, bins = bins)\n",
    "plt.xlabel(\"Sequence Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of FASTA Sequence Lengths (TRAIN)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the sequences are below 5K amino acids long. There are a few very long sequences as well (> 35K amino acids).\n",
    "\n",
    "Let us have a look at some numeric stats as well as the 99th percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(lengths).describe())\n",
    "print('')\n",
    "print('')\n",
    "p99 = np.percentile(lengths, 99)\n",
    "print(\"99th percentile sequence length:\", p99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the proteins are really tiny (< 10 amino acids). Guess in that case, they should be called peptides, not proteins. :)\n",
    "\n",
    "Furthermore, 3/4 of all proteins are <= 526 amino acids long (75th percentile).\n",
    "\n",
    "Now let's do the same but for the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(str(entry[\"seq\"])) for entry in test_fasta_sequences]\n",
    "\n",
    "print(pd.Series(lengths).value_counts().sort_index())\n",
    "print('')\n",
    "print('')\n",
    "p99 = np.percentile(lengths, 99)\n",
    "print(\"99th percentile sequence length:\", p99)\n",
    "\n",
    "bin_width = 100\n",
    "bins = np.arange(0, max(lengths) + bin_width, bin_width)\n",
    "plt.figure()\n",
    "plt.hist(lengths, bins = bins)\n",
    "plt.xlabel(\"Sequence Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of FASTA Sequence Lengths (TEST)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set GO Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:38.914608Z",
     "iopub.status.busy": "2025-11-08T16:34:38.914207Z",
     "iopub.status.idle": "2025-11-08T16:34:39.344237Z",
     "shell.execute_reply": "2025-11-08T16:34:39.342657Z",
     "shell.execute_reply.started": "2025-11-08T16:34:38.914582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# load training set terms\n",
    "\n",
    "train_terms_df = pd.read_csv(train_terms_file, sep=\"\\t\")\n",
    "train_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:39.345872Z",
     "iopub.status.busy": "2025-11-08T16:34:39.345539Z",
     "iopub.status.idle": "2025-11-08T16:34:39.476269Z",
     "shell.execute_reply": "2025-11-08T16:34:39.475353Z",
     "shell.execute_reply.started": "2025-11-08T16:34:39.345832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# number of unique values in each column\n",
    "\n",
    "print(f\"Number of unique entries: {train_terms_df.EntryID.nunique()}\")\n",
    "print(f\"Number of unique terms:   {train_terms_df.term.nunique()}\")\n",
    "print(f\"Number of unique aspects: {train_terms_df.aspect.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the cell above, It seems that what we have here is a *\"multi-label classification problem\"* involving 26,125 labels!**\n",
    "\n",
    "That is, for each of the FASTA sequences, we are trying to predict which of the labels apply to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:39.478152Z",
     "iopub.status.busy": "2025-11-08T16:34:39.477387Z",
     "iopub.status.idle": "2025-11-08T16:34:39.515233Z",
     "shell.execute_reply": "2025-11-08T16:34:39.514154Z",
     "shell.execute_reply.started": "2025-11-08T16:34:39.478127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# total number of terms + number of unique terms per aspect\n",
    "\n",
    "print('Total number of terms:', len(train_terms_df))\n",
    "print('')\n",
    "print(train_terms_df['aspect'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:39.516590Z",
     "iopub.status.busy": "2025-11-08T16:34:39.516270Z",
     "iopub.status.idle": "2025-11-08T16:34:39.802950Z",
     "shell.execute_reply": "2025-11-08T16:34:39.801736Z",
     "shell.execute_reply.started": "2025-11-08T16:34:39.516562Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# NO intersections between terms of different aspects (as expected)\n",
    "\n",
    "p_terms = train_terms_df[train_terms_df['aspect'] == \"P\"].term\n",
    "c_terms = train_terms_df[train_terms_df['aspect'] == \"C\"].term\n",
    "f_terms = train_terms_df[train_terms_df['aspect'] == \"F\"].term\n",
    "\n",
    "print(set(p_terms).intersection(set(c_terms)))  #\n",
    "print(set(p_terms).intersection(set(f_terms)))  # empty sets\n",
    "print(set(c_terms).intersection(set(f_terms)))  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T17:20:42.418425Z",
     "iopub.status.busy": "2025-11-08T17:20:42.418098Z",
     "iopub.status.idle": "2025-11-08T17:20:42.603110Z",
     "shell.execute_reply": "2025-11-08T17:20:42.601816Z",
     "shell.execute_reply.started": "2025-11-08T17:20:42.418402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# number of terms per training sequence on average  ==>  ~6.5\n",
    "\n",
    "train_terms_df.value_counts('EntryID').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set Taxonomies (Species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:34:39.804334Z",
     "iopub.status.busy": "2025-11-08T16:34:39.803949Z",
     "iopub.status.idle": "2025-11-08T16:34:39.871464Z",
     "shell.execute_reply": "2025-11-08T16:34:39.870579Z",
     "shell.execute_reply.started": "2025-11-08T16:34:39.804300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# species id for each fasta record in the train set\n",
    "\n",
    "train_species_df = pd.read_csv(train_taxonomy_file, sep=\"\\t\", header=None)\n",
    "train_species_df.columns = ['fasta_id', 'species_id']\n",
    "train_species_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_species_df = pd.merge(train_species_df, species_lookup_df, on='species_id', how='inner')\n",
    "train_species_df[['species_id', 'species_name']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gene Ontology DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ontology = GODag(go_file)\n",
    "\n",
    "# Example: Look up a GO term\n",
    "term = ontology[\"GO:0006915\"]\n",
    "print('term.name:', term.name)\n",
    "print('term.namespace:', term.namespace)\n",
    "# print(term.parents)\n",
    "# print(term.children)\n",
    "# print(term.level)\n",
    "# print(term.depth)\n",
    "# print(term.is_obsolete)\n",
    "# print(term.alt_ids)\n",
    "# print(term.is_a)\n",
    "\n",
    "# for documentation for the GoTerm class, refer to:\n",
    "# https://github.com/tanghaibao/goatools/blob/main/goatools/obo_parser.py#L157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# number of terms in the GO graph\n",
    "\n",
    "len(ontology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# keep elements of GO graph that also exist in training set\n",
    "\n",
    "list_of_train_terms = list(train_terms_df['term'])\n",
    "ontology_filtered = {k: ontology[k] for k in list_of_train_terms}\n",
    "len(ontology_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# look at an example GO term and its parents\n",
    "\n",
    "random_go_term = 'GO:0043371'\n",
    "random_go_term_parents = ontology_filtered[random_go_term].get_all_parents()\n",
    "\n",
    "print(ontology_filtered[random_go_term])\n",
    "print('')\n",
    "print('Parents:')\n",
    "for parent in random_go_term_parents:\n",
    "    if parent in ontology_filtered.keys():\n",
    "        print(ontology[parent])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------\n",
    "-------\n",
    "# Feature Engineering\n",
    "We'll focus only on the training set for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## propy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating features from a protein sequence\n",
    "\n",
    "def get_protein_descriptors(sequence):\n",
    "    DesObj = PyPro.GetProDes(sequence)\n",
    "\n",
    "    all_descriptors = {}\n",
    "    all_descriptors = all_descriptors | DesObj.GetAAComp()     # Amino acid compositon descriptors (20)\n",
    "    all_descriptors = all_descriptors | DesObj.GetDPComp()     # Dipeptide composition descriptors (400)\n",
    "    all_descriptors = all_descriptors | DesObj.GetCTD()        # Composition Transition Distribution descriptors (147)\n",
    "    # all_descriptors = all_descriptors | DesObj.GetGearyAuto()  # Geary autocorrelation descriptors (240)\n",
    "    # all_descriptors = all_descriptors | DesObj.GetMoranAuto()  # Moran autocorrelation descriptors (240)\n",
    "    # all_descriptors = all_descriptors | DesObj.GetQSO()        # Quasi sequence order descriptors (default is 50)\n",
    "    # all_descriptors = all_descriptors | DesObj.GetSOCN()       # Sequence order coupling numbers (default is 45)\n",
    "\n",
    "    return all_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "get_protein_descriptors(train_fasta_sequences[0]['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = {}\n",
    "for i in range(len(train_fasta_sequences)):\n",
    "    key_i = train_fasta_sequences[i]['id']\n",
    "    seq_i = train_fasta_sequences[i]['seq']\n",
    "    train_features[key_i] = get_protein_descriptors(seq_i)\n",
    "    if i % 10000 == 0:\n",
    "        print(i, '-->', datetime.now())\n",
    "\n",
    "train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESM Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ESM embeddings for the sequences ()\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")  # FASTER!\n",
    "\n",
    "# Load model\n",
    "#   For more models, check the \"Available Models and Datasets\" section at this link:\n",
    "#     https://pypi.org/project/fair-esm/#available-models\n",
    "model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()  # GPU support\n",
    "\n",
    "# number of layers\n",
    "LAYER = len(model.layers)\n",
    "\n",
    "def embed_sequence(seq):\n",
    "    batch = [(\"protein1\", seq)]\n",
    "    _, _, tokens = batch_converter(batch)\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            tokens = tokens.cuda()\n",
    "        results = model(tokens, repr_layers=[LAYER])\n",
    "    token_representations = results[\"representations\"][LAYER]\n",
    "    embedding = token_representations[0, 1:-1].mean(0)  # Mean pooling (skip CLS and EOS tokens)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        embedding = embedding.cpu()\n",
    "        \n",
    "    return embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside very long sequences that may cause out-of-memory problems\n",
    "\n",
    "max_len = 8000\n",
    "train_long_sequences = [x for x in train_fasta_sequences if len(str(x[\"seq\"])) > max_len]\n",
    "test_long_sequences  = [x for x in  test_fasta_sequences if len(str(x[\"seq\"])) > max_len]\n",
    "len(train_long_sequences), len(test_long_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences that we will generate embeddings for\n",
    "\n",
    "train_ok_sequences = [x for x in train_fasta_sequences if len(str(x[\"seq\"])) <= max_len]\n",
    "test_ok_sequences  = [x for x in  test_fasta_sequences if len(str(x[\"seq\"])) <= max_len]\n",
    "len(train_ok_sequences), len(test_ok_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features2 = {}\n",
    "for i in range(len(train_ok_sequences)):\n",
    "    key_i = train_ok_sequences[i]['id']\n",
    "    seq_i = train_ok_sequences[i]['seq']\n",
    "    train_features2[key_i] = embed_sequence(seq_i)\n",
    "    if i % 10000 == 0:\n",
    "        print(i, '-->', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate train_features & train_features2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # len(train_features2)\n",
    "# lengths = [len(str(entry[\"seq\"])) for entry in test_fasta_sequences]\n",
    "# # print(max([x for x in lengths if 5000<x<8000]))\n",
    "# print(len([x for x in lengths if x > 7000]))\n",
    "# # print(sorted([x for x in lengths if x > 10000]))\n",
    "# # tmp123 = [x['seq'] for x in test_fasta_sequences if len(x['seq']) == 7968][0]\n",
    "# # embed_sequence(tmp123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import numpy as np\n",
    "\n",
    "# # Suppose features is a list of vectors from multiple proteins\n",
    "# # e.g., features = [embed_sequence(seq) for seq in sequences.values()]\n",
    "# features = np.array(features)\n",
    "\n",
    "# pca = PCA(n_components=50)   # choose output dimension\n",
    "# reduced = pca.fit_transform(features)\n",
    "\n",
    "# print(\"Original shape:\", features.shape)\n",
    "# print(\"Reduced shape:\", reduced.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
